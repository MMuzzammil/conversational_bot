{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "infile = open('/mnt/d/gru_without_lda/word_index','rb')\n",
    "word_index = pickle.load(infile)\n",
    "infile.close()\n",
    "index_to_word = { index:word for word,index in word_index.items()}\n",
    "\n",
    "model = load_model('/mnt/d/gru_without_lda/model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence_beam_search(input_seq,beam_width=3,MAX_SEQ_LENGTH=20,vocab_size=20000):\n",
    "  index_to_word[0] = \"\"\n",
    "  target_seq = np.zeros((beam_width,MAX_SEQ_LENGTH))#to store target sequences at different time steps\n",
    "  is_complete = []#if the given sequence has been ended by \"aakhir\" token\n",
    "  fed_seq = []#sequence to be fed to predict output\n",
    "  scores = np.zeros((beam_width,))#beam scores\n",
    "  for i in range(beam_width):\n",
    "    target_seq[i,0] = word_index[\"awwal\"]\n",
    "    fed_seq.append([input_seq,target_seq[i:i+1]])\n",
    "    is_complete.append(False)\n",
    "\n",
    "  for i in range(MAX_SEQ_LENGTH-1):\n",
    "    all_candidates = []#all possible beam_width*beam_width candidates at a given time step\n",
    "    all_scores = []#their scores\n",
    "    all_bool = []#if the given seq is complete\n",
    "    for j in range(beam_width):\n",
    "      if is_complete[j]: #if the seq is complete \n",
    "        all_candidates.append(np.array(target_seq[j]))\n",
    "        all_scores+=[scores[j]]\n",
    "        all_bool+=[is_complete[j]]\n",
    "        continue\n",
    "      output = model.predict(fed_seq[j])[i]\n",
    "\n",
    "      tmp_scores = (scores[j]*((i+1)**0.7)+np.log(output).reshape(vocab_size,))/((i+2)**0.7)  #length_normalization**0.7 scores[j]+np.log(output).reshape(vocab_size,)\n",
    "      indexes = np.argsort(-1*tmp_scores)[:beam_width]#top k candidates\n",
    "      scores_of_top = np.array([tmp_scores[i] for i in indexes])\n",
    "      tmp_bool = [index_to_word[i]==\"aakhir\" for i in indexes]\n",
    "\n",
    "      for index in indexes:\n",
    "        new_candidate = np.array(target_seq[j])\n",
    "        new_candidate[i+1] = index\n",
    "\n",
    "        all_candidates.append(new_candidate)\n",
    "      \n",
    "      all_scores+=list(scores_of_top)\n",
    "      all_bool+=tmp_bool\n",
    "\n",
    "    if i==0:\n",
    "      sorted_scores_indexes = np.arange(0,beam_width) #first k candidates bcoz symmetry imposed by awwal\n",
    "    else:\n",
    "      sorted_scores_indexes = np.argsort(-1*np.array(all_scores))[:beam_width] #top k candidates from all beams\n",
    "\n",
    "    target_seq = [all_candidates[i] for i in sorted_scores_indexes]\n",
    "    scores = [all_scores[i] for i in sorted_scores_indexes]\n",
    "    is_complete = [all_bool[i] for i in sorted_scores_indexes]\n",
    "\n",
    "    fed_seq = [[input_seq,np.array(t).reshape(1,MAX_SEQ_LENGTH)] for t in target_seq]\n",
    "\n",
    "  return target_seq,scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HUMAN: hi!\n",
      "BOT:\n",
      "\n",
      "awwal you got a lot more than than than than aakhir          -1.9483557\n",
      "awwal you got a lot more than than than than than aakhir         -1.983195\n",
      "awwal you got a lot more than than than than than than than aakhir       -2.0171983\n",
      "awwal you got a lot more than than than than than than than than aakhir      -2.0424464\n",
      "awwal you got a lot more than than than than than than aakhir        -2.056576\n",
      "HUMAN: hello\n",
      "BOT:\n",
      "\n",
      "awwal you know that you shouldn't be a real aakhir           -2.3113902\n",
      "awwal you know that is you you shouldn't be a real aakhir         -2.4650555\n",
      "awwal you know that shouldn't be a real but you aakhir          -2.5453212\n",
      "awwal you know that is you you shouldn't be a real but i can do aakhir     -2.821666\n",
      "awwal you know that is you you shouldn't be a real but all the way you could be your way -3.0350852\n",
      "HUMAN: hey,how are you\n",
      "BOT:\n",
      "\n",
      "awwal all of the situation you know this is you know aakhir         -2.0356996\n",
      "awwal if you take this back to your account aakhir           -2.1426296\n",
      "awwal all of the situation you know this is you know you know aakhir       -2.397793\n",
      "awwal all of the situation you have to take care of the situation aakhir       -2.5223155\n",
      "awwal all of the situation you know this is you know i have to have aakhir     -2.5391312\n",
      "HUMAN: you are working fine i guess\n",
      "BOT:\n",
      "\n",
      "awwal well i don't know why but i don't want to know aakhir        -2.5699036\n",
      "awwal well i don't know why but i don't want to know what happened to you aakhir    -2.6210415\n",
      "awwal well i don't know why but i don't want to work with him aakhir      -2.6683893\n",
      "awwal well i don't know why but i don't want to know what is you aakhir     -2.703695\n",
      "awwal well i don't know why but i don't want to know what happened to you with all of you -2.9367347\n",
      "HUMAN: you are stupid\n",
      "BOT:\n",
      "\n",
      "awwal if we have any idea to show where where aakhir          -2.2724738\n",
      "awwal if we want to get through the show aakhir           -2.3592994\n",
      "awwal if we have any idea to show where aakhir           -2.374307\n",
      "awwal if we have any idea to show you aakhir           -2.4649506\n",
      "awwal if we have any idea to show you we don't even a answer aakhir      -2.5061638\n",
      "HUMAN: what time is it\n",
      "BOT:\n",
      "\n",
      "awwal there's gotta take to take this right now aakhir           -2.3266394\n",
      "awwal there's gotta take to take this place aakhir            -2.32703\n",
      "awwal there's a lot of things i can tell about it aakhir         -2.3801181\n",
      "awwal there's gotta take to take this right now that does not you aakhir       -2.5776794\n",
      "awwal there's gotta take to take this right now that does not that you aakhir      -2.737673\n",
      "HUMAN: have you learnt the semantics\n",
      "BOT:\n",
      "\n",
      "awwal all of a very good for a moment for a long girl aakhir       -2.4517322\n",
      "awwal all of a very good for a moment for this long aakhir        -2.4562984\n",
      "awwal all of a very good for a moment for this aakhir         -2.502056\n",
      "awwal all of a very good for a moment for a long long aakhir       -2.5514555\n",
      "awwal all of the end of the world and all the earth aakhir        -2.551521\n",
      "HUMAN: you are not context-aware\n",
      "BOT:\n",
      "\n",
      "awwal i don't know what you're doing about aakhir            -2.3302634\n",
      "awwal i don't know what you're doing about this aakhir           -2.5328457\n",
      "awwal i don't want to play with me anymore what happened aakhir         -2.5924513\n",
      "awwal i don't want to play with me anymore aakhir           -2.670633\n",
      "awwal i don't want to play with me anymore what aakhir          -2.769098\n",
      "HUMAN: i think your performance is better\n",
      "BOT:\n",
      "\n",
      "awwal this is a great of you to know about you aakhir         -2.2583945\n",
      "awwal this is a great of you to have this aakhir          -2.2586198\n",
      "awwal this is the first century of the century of the century of the century of the century of the -2.2964542\n",
      "awwal this is the first century of the century of the century of the century of the century aakhir  -2.332108\n",
      "awwal this is the first century of the century of the real question aakhir       -2.3333988\n",
      "HUMAN: do you like bananas\n",
      "BOT:\n",
      "\n",
      "awwal it was one one who gifted at the house aakhir          -1.9812646\n",
      "awwal it is one one who can make more than than than than than than than than than than than -2.0161774\n",
      "awwal it is one one who can make more than than than than than than than than than than aakhir -2.0948746\n",
      "awwal it is one one who can make more than than than than than than than than aakhir   -2.123147\n",
      "awwal it is one one who can make more than than than than than than than than than aakhir  -2.161614\n",
      "HUMAN: sometimes you misbehave\n",
      "BOT:\n",
      "\n",
      "awwal i was like that that was like that he was at him aakhir       -2.6199155\n",
      "awwal i was like that that was like that he was at us aakhir       -2.8426301\n",
      "awwal i was like that that was like that he was at the side of the stairs aakhir   -2.900083\n",
      "awwal i was like that that was like that he was at the way aakhir      -2.9140682\n",
      "awwal i was like that that was like that he was at the side of the way aakhir   -3.00813\n",
      "HUMAN: do you go to school?\n",
      "BOT:\n",
      "\n",
      "awwal it's only one of the people but you didn't notice me aakhir        -2.2986178\n",
      "awwal it's only one of the people that you are aakhir          -2.3449051\n",
      "awwal it's only one of the people that you didn't notice me aakhir        -2.3569043\n",
      "awwal it's only one of the people that you didn't notice you all aakhir       -2.5519729\n",
      "awwal it's only one of the people that you didn't notice you all the same aakhir     -2.599376\n",
      "HUMAN: i have started to like you\n",
      "BOT:\n",
      "\n",
      "awwal you know you can tell me to this whole aakhir          -2.7259195\n",
      "awwal you know you can tell me to this whole world aakhir         -2.8671687\n",
      "awwal it's a little early i take you to stay early early aakhir        -3.1394734\n",
      "awwal it's a little early i take you to my little aakhir         -3.2612677\n",
      "awwal it's a little early i take you to my little more more more even you can tell you to -3.5534806\n",
      "HUMAN: you are cruel\n",
      "BOT:\n",
      "\n",
      "awwal if he didn't you so he didn't want to talk aakhir         -2.1751146\n",
      "awwal if he didn't you so he didn't want to talk to you aakhir       -2.2103074\n",
      "awwal if he didn't you so he didn't want to talk to him aakhir       -2.2199147\n",
      "awwal if he didn't you so he didn't want to talk you aakhir        -2.2326956\n",
      "awwal if he didn't you so he didn't want to talk about aakhir        -2.324458\n",
      "HUMAN: i too do not want to talk to you\n",
      "BOT:\n",
      "\n",
      "awwal well i don't want to talk to me aakhir           -2.591633\n",
      "awwal well i don't want to worry the government guard aakhir          -2.6824954\n",
      "awwal well i don't want to be talking about aakhir           -2.6861463\n",
      "awwal well i don't want to insult me the truth aakhir          -2.7309272\n",
      "awwal well i don't want to worry the government guard to be rude aakhir       -2.866628\n",
      "HUMAN: i created you\n",
      "BOT:\n",
      "\n",
      "awwal there's a lot of questions to you aakhir            -2.1391299\n",
      "awwal there's a lot of people who don't even it aakhir          -2.388766\n",
      "awwal there's a lot of questions to you about aakhir           -2.4138093\n",
      "awwal well i don't wanna take any more of you aakhir          -2.414321\n",
      "awwal there's a lot of questions to you about this aakhir          -2.4775374\n",
      "HUMAN: exit\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tokenizer = Tokenizer(num_words=20000,oov_token=\"<oov>\")\n",
    "tokenizer.word_index = word_index\n",
    "\n",
    "while True:\n",
    "  query = str(input(\"HUMAN: \"))\n",
    "  if query=='exit':\n",
    "        break\n",
    "  else:\n",
    "        query = tokenizer.texts_to_sequences([query])[0]\n",
    "        query = pad_sequences([query],maxlen=20,padding='post')\n",
    "        responses,scores = decode_sequence_beam_search(query,beam_width=5)\n",
    "        print(\"BOT:\\n\")\n",
    "        for i,r in enumerate(responses):\n",
    "            s = ' '.join([index_to_word[t] for t in responses[i]])\n",
    "            print(s,scores[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python36964bit1f460b5b3cd84ed4b0f197016a7a1a56"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
