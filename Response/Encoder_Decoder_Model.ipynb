{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.6.9 64-bit",
      "language": "python",
      "name": "python36964bit1f460b5b3cd84ed4b0f197016a7a1a56"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Encoder_Decoder_Model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpJRSv2KCnar",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 657
        },
        "outputId": "9df45112-0f3c-44f4-c537-35b455a097aa"
      },
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n",
        "import zipfile\n",
        "with zipfile.ZipFile('/content/glove.6B.zip','r') as zip:\n",
        "  zip.extractall('/content/')\n",
        "\n",
        "!wget http://opus.nlpl.eu/download.php?f=OpenSubtitles/v2018/mono/OpenSubtitles.raw.en.gz\n",
        "!gunzip -k /content/download.php?f=OpenSubtitles%2Fv2018%2Fmono%2FOpenSubtitles.raw.en.gz\n",
        "!mkdir lines\n",
        "!split -a 3 -l 100000 download.php?f=OpenSubtitles%2Fv2018%2Fmono%2FOpenSubtitles.raw.en lines/lines-"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-06-27 06:39:53--  http://nlp.stanford.edu/data/glove.6B.zip\n",
            "Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n",
            "--2020-06-27 06:39:53--  https://nlp.stanford.edu/data/glove.6B.zip\n",
            "Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n",
            "HTTP request sent, awaiting response... 301 Moved Permanently\n",
            "Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n",
            "--2020-06-27 06:39:54--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n",
            "Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n",
            "Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 862182613 (822M) [application/zip]\n",
            "Saving to: ‘glove.6B.zip’\n",
            "\n",
            "glove.6B.zip        100%[===================>] 822.24M  2.08MB/s    in 6m 30s  \n",
            "\n",
            "2020-06-27 06:46:23 (2.11 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n",
            "--2020-06-27 06:46:50--  http://opus.nlpl.eu/download.php?f=OpenSubtitles/v2018/mono/OpenSubtitles.raw.en.gz\n",
            "Resolving opus.nlpl.eu (opus.nlpl.eu)... 193.166.25.9\n",
            "Connecting to opus.nlpl.eu (opus.nlpl.eu)|193.166.25.9|:80... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://object.pouta.csc.fi/OPUS-OpenSubtitles/v2018/mono/en.txt.gz [following]\n",
            "--2020-06-27 06:46:50--  https://object.pouta.csc.fi/OPUS-OpenSubtitles/v2018/mono/en.txt.gz\n",
            "Resolving object.pouta.csc.fi (object.pouta.csc.fi)... 86.50.254.18, 86.50.254.19\n",
            "Connecting to object.pouta.csc.fi (object.pouta.csc.fi)|86.50.254.18|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 3663376519 (3.4G) [application/gzip]\n",
            "Saving to: ‘download.php?f=OpenSubtitles%2Fv2018%2Fmono%2FOpenSubtitles.raw.en.gz’\n",
            "\n",
            "download.php?f=Open 100%[===================>]   3.41G  32.5MB/s    in 88s     \n",
            "\n",
            "2020-06-27 06:48:23 (39.8 MB/s) - ‘download.php?f=OpenSubtitles%2Fv2018%2Fmono%2FOpenSubtitles.raw.en.gz’ saved [3663376519/3663376519]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiCJPTQaG5_4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4dd9c2b6-0509-4c2b-e62d-aaf907485641"
      },
      "source": [
        "import os\n",
        "files = os.listdir('/content/lines')\n",
        "print(len(files))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "4415\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TRYpnLhxChzq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7347ef39-2d2c-406f-dcac-eff8d642d96b"
      },
      "source": [
        "files = files[:100]\n",
        "min_len = 40\n",
        "max_len = 100\n",
        "context = []\n",
        "response = []\n",
        "\n",
        "for f in files:\n",
        "  file = open('/content/lines/'+f)\n",
        "  i = 0\n",
        "  for j,line in enumerate(file):\n",
        "      if len(line)<min_len or len(line)>max_len:\n",
        "        continue\n",
        "      if i%2==0:\n",
        "          context.append(line)\n",
        "          i+=1\n",
        "      else:\n",
        "          response.append(\"awwal \"+line+\" aakhir\")\n",
        "          i+=1\n",
        "\n",
        "\n",
        "print(len(response),len(context))\n",
        "context = context[:533232]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1083217 1083267\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jV9w-b-lChzx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hyjWes2lChz0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_SEQ_LENGTH = 20\n",
        "EMBEDDING_DIM = 50\n",
        "vocab_size = 20000\n",
        "tokenizer = Tokenizer(num_words=vocab_size,oov_token=\"<oov>\")\n",
        "tokenizer.fit_on_texts(context+response)\n",
        "\n",
        "word_index = {word:index for word,index in tokenizer.word_index.items() if index<vocab_size }\n",
        "index_to_word = { index:word for word,index in word_index.items()}\n",
        "\n",
        "context_seq = tokenizer.texts_to_sequences(context)\n",
        "response_seq = tokenizer.texts_to_sequences(response)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dANJC3gRChz2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "cda8b0d8-5fed-4b9b-d2f8-7792a95668c9"
      },
      "source": [
        "\n",
        "encoder_inputs = []\n",
        "decoder_inputs = []\n",
        "decoder_outputs = []\n",
        "for i in range(len(context_seq)):\n",
        "    if not(len(context_seq[i])>MAX_SEQ_LENGTH or len(response_seq[i])-1>MAX_SEQ_LENGTH):\n",
        "        encoder_inputs.append(context_seq[i])\n",
        "        decoder_inputs.append(response_seq[i][:-1])\n",
        "        decoder_outputs.append(response_seq[i][1:])\n",
        "\n",
        "encoder_inputs = pad_sequences(encoder_inputs,maxlen = MAX_SEQ_LENGTH,padding='post',truncating='post')\n",
        "decoder_inputs = pad_sequences(decoder_inputs,maxlen = MAX_SEQ_LENGTH,padding='post',truncating='post')\n",
        "decoder_outputs = pad_sequences(decoder_outputs,maxlen = MAX_SEQ_LENGTH,padding='post',truncating='post')\n",
        "\n",
        "print(len(encoder_inputs),len(decoder_inputs),len(decoder_outputs))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "527500 527500 527500\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3HMMyqIOChz5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "22b13e9b-2119-4e91-cdce-6c1cbce1e663"
      },
      "source": [
        "print(decoder_outputs[:5])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[   51    30  1146    12   643  9921    23    77     3     0     0     0\n",
            "      0     0     0     0     0     0     0     0]\n",
            " [  317    45   208    24   217    15    19   929     3     0     0     0\n",
            "      0     0     0     0     0     0     0     0]\n",
            " [   39    31   565     6 18887    55    28  4049   138   146  2243     3\n",
            "      0     0     0     0     0     0     0     0]\n",
            " [   46     7    41   128    10   150     1     1  4085    23     4 16068\n",
            "     22   538     3     0     0     0     0     0]\n",
            " [   31    38     5  3161   113    49    16   531     3     0     0     0\n",
            "      0     0     0     0     0     0     0     0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhhrwX7tChz8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c44b2e1b-ff77-4c51-91d5-1402674eb0f6"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "embeddings_index = {}\n",
        "f = open(os.path.join('/content', 'glove.6B.50d.txt'))\n",
        "for line in f:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    coefs = np.asarray(values[1:], dtype='float32')\n",
        "    embeddings_index[word] = coefs\n",
        "f.close()\n",
        "\n",
        "print('Found %s word vectors.' % len(embeddings_index))\n",
        "\n",
        "embedding_matrix = np.zeros((len(word_index) + 1, EMBEDDING_DIM))\n",
        "for word, i in word_index.items():\n",
        "    embedding_vector = embeddings_index.get(word)\n",
        "    if embedding_vector is not None:\n",
        "        # words not found in embedding index will be all-zeros.\n",
        "        embedding_matrix[i] = embedding_vector\n",
        "    else:\n",
        "        embedding_matrix[i] = np.random.randn(1,EMBEDDING_DIM)\n",
        "\n",
        "from tensorflow.keras.layers import Embedding\n",
        "\n",
        "embedding_layer = Embedding(len(word_index) + 1,\n",
        "                            EMBEDDING_DIM,\n",
        "                            weights=[embedding_matrix],\n",
        "                            input_length=MAX_SEQ_LENGTH,\n",
        "                            #mask_zero = True,\n",
        "                            trainable=False)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 400000 word vectors.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXfBJI1WChz_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import *\n",
        "from tensorflow.keras import Model"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rni-dujHcFcD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Defined shared layers as global variables\n",
        "repeator = RepeatVector(MAX_SEQ_LENGTH)\n",
        "concatenator = Concatenate(axis=-1)\n",
        "densor1 = Dense(10, activation = \"tanh\")\n",
        "densor2 = Dense(1, activation = \"softmax\")\n",
        "dotor = Dot(axes = 1)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHIIB1aQcj0d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def one_step_attention(a, s_prev):\n",
        "    #calculating context vector\n",
        "    s_prev = repeator(s_prev)\n",
        "    concat = concatenator([a,s_prev])\n",
        "    e = densor1(concat)\n",
        "    alphas = densor2(e)\n",
        "    context = dotor([alphas,a])\n",
        "    \n",
        "    return context"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_fZKQcpCCh0C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encoder_decoder_model():\n",
        "    hidden_dim = 512\n",
        "    \n",
        "    #encoder\n",
        "    encoder_inputs = Input(shape=(MAX_SEQ_LENGTH,))\n",
        "    emb_en_input = embedding_layer(encoder_inputs)\n",
        "    #encoder_lstm = LSTM(hidden_dim,return_sequences=True,return_state=True)\n",
        "    encoder_gru = GRU(hidden_dim,return_sequences=True,return_state=True)\n",
        "    #whole_encoder_outputs,state_h,state_c = encoder_lstm(emb_en_input)\n",
        "    whole_encoder_outputs,state_h = encoder_gru(emb_en_input)\n",
        "    #encoder_states = [state_h,state_c]\n",
        "    encoder_states = [state_h]\n",
        "\n",
        "    \n",
        "    #getting context vector\n",
        "    a = whole_encoder_outputs #for one step attention\n",
        "    s = state_h\n",
        "    #c = state_c\n",
        "    #decoder model for training\n",
        "    decoder_inputs = Input(shape=(MAX_SEQ_LENGTH,))\n",
        "    emb_de_input = embedding_layer(decoder_inputs)\n",
        "    #decoder_lstm = LSTM(hidden_dim,return_state=True)\n",
        "    decoder_gru = GRU(hidden_dim,return_state=True)\n",
        "    decoder_dense  = Dense(vocab_size,activation=\"softmax\")\n",
        "    outputs = []\n",
        "    for t in range(MAX_SEQ_LENGTH): #number of output time steps\n",
        "      context = one_step_attention(a,s) \n",
        "      concatenated_input = concatenator([context,emb_de_input[:,t:t+1]])\n",
        "      decoder_output,s = decoder_gru(concatenated_input,initial_state=[s])\n",
        "      decoder_output = decoder_dense(decoder_output)\n",
        "      outputs.append(decoder_output)\n",
        "    decoder_outputs = outputs#complete output\n",
        "    \n",
        "\n",
        "    #model for training\n",
        "    model = Model(inputs=[encoder_inputs,decoder_inputs],outputs=decoder_outputs)\n",
        "   \n",
        "    return model"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kbf4Mk8cCh0E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = encoder_decoder_model()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlECx66r_eH8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer=\"adam\",loss=\"sparse_categorical_crossentropy\",metrics=['accuracy'])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wmKsb53n4phT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d3729ed9-5022-4377-dc1e-9afcda1a13cc"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "embedding (Embedding)           (None, 20, 50)       1000000     input_1[0][0]                    \n",
            "                                                                 input_2[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "gru (GRU)                       [(None, 20, 512), (N 866304      embedding[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "repeat_vector (RepeatVector)    (None, 20, 512)      0           gru[0][1]                        \n",
            "                                                                 gru_1[0][1]                      \n",
            "                                                                 gru_1[1][1]                      \n",
            "                                                                 gru_1[2][1]                      \n",
            "                                                                 gru_1[3][1]                      \n",
            "                                                                 gru_1[4][1]                      \n",
            "                                                                 gru_1[5][1]                      \n",
            "                                                                 gru_1[6][1]                      \n",
            "                                                                 gru_1[7][1]                      \n",
            "                                                                 gru_1[8][1]                      \n",
            "                                                                 gru_1[9][1]                      \n",
            "                                                                 gru_1[10][1]                     \n",
            "                                                                 gru_1[11][1]                     \n",
            "                                                                 gru_1[12][1]                     \n",
            "                                                                 gru_1[13][1]                     \n",
            "                                                                 gru_1[14][1]                     \n",
            "                                                                 gru_1[15][1]                     \n",
            "                                                                 gru_1[16][1]                     \n",
            "                                                                 gru_1[17][1]                     \n",
            "                                                                 gru_1[18][1]                     \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       multiple             0           gru[0][0]                        \n",
            "                                                                 repeat_vector[0][0]              \n",
            "                                                                 dot[0][0]                        \n",
            "                                                                 tf_op_layer_strided_slice[0][0]  \n",
            "                                                                 gru[0][0]                        \n",
            "                                                                 repeat_vector[1][0]              \n",
            "                                                                 dot[1][0]                        \n",
            "                                                                 tf_op_layer_strided_slice_1[0][0]\n",
            "                                                                 gru[0][0]                        \n",
            "                                                                 repeat_vector[2][0]              \n",
            "                                                                 dot[2][0]                        \n",
            "                                                                 tf_op_layer_strided_slice_2[0][0]\n",
            "                                                                 gru[0][0]                        \n",
            "                                                                 repeat_vector[3][0]              \n",
            "                                                                 dot[3][0]                        \n",
            "                                                                 tf_op_layer_strided_slice_3[0][0]\n",
            "                                                                 gru[0][0]                        \n",
            "                                                                 repeat_vector[4][0]              \n",
            "                                                                 dot[4][0]                        \n",
            "                                                                 tf_op_layer_strided_slice_4[0][0]\n",
            "                                                                 gru[0][0]                        \n",
            "                                                                 repeat_vector[5][0]              \n",
            "                                                                 dot[5][0]                        \n",
            "                                                                 tf_op_layer_strided_slice_5[0][0]\n",
            "                                                                 gru[0][0]                        \n",
            "                                                                 repeat_vector[6][0]              \n",
            "                                                                 dot[6][0]                        \n",
            "                                                                 tf_op_layer_strided_slice_6[0][0]\n",
            "                                                                 gru[0][0]                        \n",
            "                                                                 repeat_vector[7][0]              \n",
            "                                                                 dot[7][0]                        \n",
            "                                                                 tf_op_layer_strided_slice_7[0][0]\n",
            "                                                                 gru[0][0]                        \n",
            "                                                                 repeat_vector[8][0]              \n",
            "                                                                 dot[8][0]                        \n",
            "                                                                 tf_op_layer_strided_slice_8[0][0]\n",
            "                                                                 gru[0][0]                        \n",
            "                                                                 repeat_vector[9][0]              \n",
            "                                                                 dot[9][0]                        \n",
            "                                                                 tf_op_layer_strided_slice_9[0][0]\n",
            "                                                                 gru[0][0]                        \n",
            "                                                                 repeat_vector[10][0]             \n",
            "                                                                 dot[10][0]                       \n",
            "                                                                 tf_op_layer_strided_slice_10[0][0\n",
            "                                                                 gru[0][0]                        \n",
            "                                                                 repeat_vector[11][0]             \n",
            "                                                                 dot[11][0]                       \n",
            "                                                                 tf_op_layer_strided_slice_11[0][0\n",
            "                                                                 gru[0][0]                        \n",
            "                                                                 repeat_vector[12][0]             \n",
            "                                                                 dot[12][0]                       \n",
            "                                                                 tf_op_layer_strided_slice_12[0][0\n",
            "                                                                 gru[0][0]                        \n",
            "                                                                 repeat_vector[13][0]             \n",
            "                                                                 dot[13][0]                       \n",
            "                                                                 tf_op_layer_strided_slice_13[0][0\n",
            "                                                                 gru[0][0]                        \n",
            "                                                                 repeat_vector[14][0]             \n",
            "                                                                 dot[14][0]                       \n",
            "                                                                 tf_op_layer_strided_slice_14[0][0\n",
            "                                                                 gru[0][0]                        \n",
            "                                                                 repeat_vector[15][0]             \n",
            "                                                                 dot[15][0]                       \n",
            "                                                                 tf_op_layer_strided_slice_15[0][0\n",
            "                                                                 gru[0][0]                        \n",
            "                                                                 repeat_vector[16][0]             \n",
            "                                                                 dot[16][0]                       \n",
            "                                                                 tf_op_layer_strided_slice_16[0][0\n",
            "                                                                 gru[0][0]                        \n",
            "                                                                 repeat_vector[17][0]             \n",
            "                                                                 dot[17][0]                       \n",
            "                                                                 tf_op_layer_strided_slice_17[0][0\n",
            "                                                                 gru[0][0]                        \n",
            "                                                                 repeat_vector[18][0]             \n",
            "                                                                 dot[18][0]                       \n",
            "                                                                 tf_op_layer_strided_slice_18[0][0\n",
            "                                                                 gru[0][0]                        \n",
            "                                                                 repeat_vector[19][0]             \n",
            "                                                                 dot[19][0]                       \n",
            "                                                                 tf_op_layer_strided_slice_19[0][0\n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 20, 10)       10250       concatenate[0][0]                \n",
            "                                                                 concatenate[2][0]                \n",
            "                                                                 concatenate[4][0]                \n",
            "                                                                 concatenate[6][0]                \n",
            "                                                                 concatenate[8][0]                \n",
            "                                                                 concatenate[10][0]               \n",
            "                                                                 concatenate[12][0]               \n",
            "                                                                 concatenate[14][0]               \n",
            "                                                                 concatenate[16][0]               \n",
            "                                                                 concatenate[18][0]               \n",
            "                                                                 concatenate[20][0]               \n",
            "                                                                 concatenate[22][0]               \n",
            "                                                                 concatenate[24][0]               \n",
            "                                                                 concatenate[26][0]               \n",
            "                                                                 concatenate[28][0]               \n",
            "                                                                 concatenate[30][0]               \n",
            "                                                                 concatenate[32][0]               \n",
            "                                                                 concatenate[34][0]               \n",
            "                                                                 concatenate[36][0]               \n",
            "                                                                 concatenate[38][0]               \n",
            "__________________________________________________________________________________________________\n",
            "input_2 (InputLayer)            [(None, 20)]         0                                            \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 20, 1)        11          dense[0][0]                      \n",
            "                                                                 dense[1][0]                      \n",
            "                                                                 dense[2][0]                      \n",
            "                                                                 dense[3][0]                      \n",
            "                                                                 dense[4][0]                      \n",
            "                                                                 dense[5][0]                      \n",
            "                                                                 dense[6][0]                      \n",
            "                                                                 dense[7][0]                      \n",
            "                                                                 dense[8][0]                      \n",
            "                                                                 dense[9][0]                      \n",
            "                                                                 dense[10][0]                     \n",
            "                                                                 dense[11][0]                     \n",
            "                                                                 dense[12][0]                     \n",
            "                                                                 dense[13][0]                     \n",
            "                                                                 dense[14][0]                     \n",
            "                                                                 dense[15][0]                     \n",
            "                                                                 dense[16][0]                     \n",
            "                                                                 dense[17][0]                     \n",
            "                                                                 dense[18][0]                     \n",
            "                                                                 dense[19][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "dot (Dot)                       (None, 1, 512)       0           dense_1[0][0]                    \n",
            "                                                                 gru[0][0]                        \n",
            "                                                                 dense_1[1][0]                    \n",
            "                                                                 gru[0][0]                        \n",
            "                                                                 dense_1[2][0]                    \n",
            "                                                                 gru[0][0]                        \n",
            "                                                                 dense_1[3][0]                    \n",
            "                                                                 gru[0][0]                        \n",
            "                                                                 dense_1[4][0]                    \n",
            "                                                                 gru[0][0]                        \n",
            "                                                                 dense_1[5][0]                    \n",
            "                                                                 gru[0][0]                        \n",
            "                                                                 dense_1[6][0]                    \n",
            "                                                                 gru[0][0]                        \n",
            "                                                                 dense_1[7][0]                    \n",
            "                                                                 gru[0][0]                        \n",
            "                                                                 dense_1[8][0]                    \n",
            "                                                                 gru[0][0]                        \n",
            "                                                                 dense_1[9][0]                    \n",
            "                                                                 gru[0][0]                        \n",
            "                                                                 dense_1[10][0]                   \n",
            "                                                                 gru[0][0]                        \n",
            "                                                                 dense_1[11][0]                   \n",
            "                                                                 gru[0][0]                        \n",
            "                                                                 dense_1[12][0]                   \n",
            "                                                                 gru[0][0]                        \n",
            "                                                                 dense_1[13][0]                   \n",
            "                                                                 gru[0][0]                        \n",
            "                                                                 dense_1[14][0]                   \n",
            "                                                                 gru[0][0]                        \n",
            "                                                                 dense_1[15][0]                   \n",
            "                                                                 gru[0][0]                        \n",
            "                                                                 dense_1[16][0]                   \n",
            "                                                                 gru[0][0]                        \n",
            "                                                                 dense_1[17][0]                   \n",
            "                                                                 gru[0][0]                        \n",
            "                                                                 dense_1[18][0]                   \n",
            "                                                                 gru[0][0]                        \n",
            "                                                                 dense_1[19][0]                   \n",
            "                                                                 gru[0][0]                        \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice (Tens [(None, 1, 50)]      0           embedding[1][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "gru_1 (GRU)                     [(None, 512), (None, 1652736     concatenate[1][0]                \n",
            "                                                                 gru[0][1]                        \n",
            "                                                                 concatenate[3][0]                \n",
            "                                                                 gru_1[0][1]                      \n",
            "                                                                 concatenate[5][0]                \n",
            "                                                                 gru_1[1][1]                      \n",
            "                                                                 concatenate[7][0]                \n",
            "                                                                 gru_1[2][1]                      \n",
            "                                                                 concatenate[9][0]                \n",
            "                                                                 gru_1[3][1]                      \n",
            "                                                                 concatenate[11][0]               \n",
            "                                                                 gru_1[4][1]                      \n",
            "                                                                 concatenate[13][0]               \n",
            "                                                                 gru_1[5][1]                      \n",
            "                                                                 concatenate[15][0]               \n",
            "                                                                 gru_1[6][1]                      \n",
            "                                                                 concatenate[17][0]               \n",
            "                                                                 gru_1[7][1]                      \n",
            "                                                                 concatenate[19][0]               \n",
            "                                                                 gru_1[8][1]                      \n",
            "                                                                 concatenate[21][0]               \n",
            "                                                                 gru_1[9][1]                      \n",
            "                                                                 concatenate[23][0]               \n",
            "                                                                 gru_1[10][1]                     \n",
            "                                                                 concatenate[25][0]               \n",
            "                                                                 gru_1[11][1]                     \n",
            "                                                                 concatenate[27][0]               \n",
            "                                                                 gru_1[12][1]                     \n",
            "                                                                 concatenate[29][0]               \n",
            "                                                                 gru_1[13][1]                     \n",
            "                                                                 concatenate[31][0]               \n",
            "                                                                 gru_1[14][1]                     \n",
            "                                                                 concatenate[33][0]               \n",
            "                                                                 gru_1[15][1]                     \n",
            "                                                                 concatenate[35][0]               \n",
            "                                                                 gru_1[16][1]                     \n",
            "                                                                 concatenate[37][0]               \n",
            "                                                                 gru_1[17][1]                     \n",
            "                                                                 concatenate[39][0]               \n",
            "                                                                 gru_1[18][1]                     \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_1 (Te [(None, 1, 50)]      0           embedding[1][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_2 (Te [(None, 1, 50)]      0           embedding[1][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_3 (Te [(None, 1, 50)]      0           embedding[1][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_4 (Te [(None, 1, 50)]      0           embedding[1][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_5 (Te [(None, 1, 50)]      0           embedding[1][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_6 (Te [(None, 1, 50)]      0           embedding[1][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_7 (Te [(None, 1, 50)]      0           embedding[1][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_8 (Te [(None, 1, 50)]      0           embedding[1][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_9 (Te [(None, 1, 50)]      0           embedding[1][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_10 (T [(None, 1, 50)]      0           embedding[1][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_11 (T [(None, 1, 50)]      0           embedding[1][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_12 (T [(None, 1, 50)]      0           embedding[1][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_13 (T [(None, 1, 50)]      0           embedding[1][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_14 (T [(None, 1, 50)]      0           embedding[1][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_15 (T [(None, 1, 50)]      0           embedding[1][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_16 (T [(None, 1, 50)]      0           embedding[1][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_17 (T [(None, 1, 50)]      0           embedding[1][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_18 (T [(None, 1, 50)]      0           embedding[1][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "tf_op_layer_strided_slice_19 (T [(None, 1, 50)]      0           embedding[1][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "dense_2 (Dense)                 (None, 20000)        10260000    gru_1[0][0]                      \n",
            "                                                                 gru_1[1][0]                      \n",
            "                                                                 gru_1[2][0]                      \n",
            "                                                                 gru_1[3][0]                      \n",
            "                                                                 gru_1[4][0]                      \n",
            "                                                                 gru_1[5][0]                      \n",
            "                                                                 gru_1[6][0]                      \n",
            "                                                                 gru_1[7][0]                      \n",
            "                                                                 gru_1[8][0]                      \n",
            "                                                                 gru_1[9][0]                      \n",
            "                                                                 gru_1[10][0]                     \n",
            "                                                                 gru_1[11][0]                     \n",
            "                                                                 gru_1[12][0]                     \n",
            "                                                                 gru_1[13][0]                     \n",
            "                                                                 gru_1[14][0]                     \n",
            "                                                                 gru_1[15][0]                     \n",
            "                                                                 gru_1[16][0]                     \n",
            "                                                                 gru_1[17][0]                     \n",
            "                                                                 gru_1[18][0]                     \n",
            "                                                                 gru_1[19][0]                     \n",
            "==================================================================================================\n",
            "Total params: 13,789,301\n",
            "Trainable params: 12,789,301\n",
            "Non-trainable params: 1,000,000\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLNtWDFOCh0G",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a2f02247-7781-4aa3-ebfb-620cb3c11655"
      },
      "source": [
        "print(encoder_inputs.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(527500, 20)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tbOB4rCrR7sd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "encoder_inputs = encoder_inputs[:100000]\n",
        "decoder_inputs = decoder_inputs[:100000]\n",
        "decoder_outputs = decoder_outputs[:100000]"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "na-UlRTBCh0I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_generator(batch_size = 64):\n",
        "    i = 0\n",
        "    indexes = np.arange(len(encoder_inputs)//batch_size)\n",
        "    while True:\n",
        "        if(i>=len(indexes)):\n",
        "            i = 0\n",
        "            np.random.shuffle(indexes)\n",
        "        X1  = encoder_inputs[indexes[i]*batch_size:(indexes[i]+1)*batch_size]\n",
        "        X2  = decoder_inputs[indexes[i]*batch_size:(indexes[i]+1)*batch_size]\n",
        "        Y  =  decoder_outputs[indexes[i]*batch_size:(indexes[i]+1)*batch_size]\n",
        "        Y = list(Y.swapaxes(0,1))\n",
        "        i+=1\n",
        "        yield([X1,X2],list(Y))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rGdy-lT_N48u",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch = 64\n",
        "datagen = data_generator(batch_size=batch)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SxmBoawUCh0K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "outputId": "44ade673-d60d-44df-e52b-a59dd6230713"
      },
      "source": [
        "model.fit(datagen,steps_per_epoch=len(decoder_inputs)//batch,epochs=10)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "1562/1562 [==============================] - 442s 283ms/step - loss: 74.1346 - dense_2_loss: 5.4838 - dense_2_1_loss: 6.2422 - dense_2_2_loss: 6.3892 - dense_2_3_loss: 6.5304 - dense_2_4_loss: 6.5747 - dense_2_5_loss: 6.6452 - dense_2_6_loss: 6.6239 - dense_2_7_loss: 6.3520 - dense_2_8_loss: 5.5996 - dense_2_9_loss: 4.5714 - dense_2_10_loss: 3.5233 - dense_2_11_loss: 2.7082 - dense_2_12_loss: 2.0443 - dense_2_13_loss: 1.5191 - dense_2_14_loss: 1.1137 - dense_2_15_loss: 0.8217 - dense_2_16_loss: 0.5777 - dense_2_17_loss: 0.3854 - dense_2_18_loss: 0.2591 - dense_2_19_loss: 0.1697 - dense_2_accuracy: 0.0977 - dense_2_1_accuracy: 0.0520 - dense_2_2_accuracy: 0.0502 - dense_2_3_accuracy: 0.0483 - dense_2_4_accuracy: 0.0470 - dense_2_5_accuracy: 0.0465 - dense_2_6_accuracy: 0.0501 - dense_2_7_accuracy: 0.0953 - dense_2_8_accuracy: 0.2121 - dense_2_9_accuracy: 0.3725 - dense_2_10_accuracy: 0.5196 - dense_2_11_accuracy: 0.6381 - dense_2_12_accuracy: 0.7313 - dense_2_13_accuracy: 0.8028 - dense_2_14_accuracy: 0.8615 - dense_2_15_accuracy: 0.9030 - dense_2_16_accuracy: 0.9358 - dense_2_17_accuracy: 0.9629 - dense_2_18_accuracy: 0.9824 - dense_2_19_accuracy: 0.9942\n",
            "Epoch 2/10\n",
            "1562/1562 [==============================] - 442s 283ms/step - loss: 65.1486 - dense_2_loss: 5.1861 - dense_2_1_loss: 5.5428 - dense_2_2_loss: 5.7647 - dense_2_3_loss: 5.9231 - dense_2_4_loss: 5.9750 - dense_2_5_loss: 6.0270 - dense_2_6_loss: 6.0038 - dense_2_7_loss: 5.7252 - dense_2_8_loss: 4.9697 - dense_2_9_loss: 3.9665 - dense_2_10_loss: 2.9800 - dense_2_11_loss: 2.2362 - dense_2_12_loss: 1.6488 - dense_2_13_loss: 1.1784 - dense_2_14_loss: 0.8207 - dense_2_15_loss: 0.5680 - dense_2_16_loss: 0.3509 - dense_2_17_loss: 0.1878 - dense_2_18_loss: 0.0839 - dense_2_19_loss: 0.0101 - dense_2_accuracy: 0.1158 - dense_2_1_accuracy: 0.1028 - dense_2_2_accuracy: 0.0901 - dense_2_3_accuracy: 0.0856 - dense_2_4_accuracy: 0.0848 - dense_2_5_accuracy: 0.0873 - dense_2_6_accuracy: 0.0941 - dense_2_7_accuracy: 0.1423 - dense_2_8_accuracy: 0.2700 - dense_2_9_accuracy: 0.4266 - dense_2_10_accuracy: 0.5700 - dense_2_11_accuracy: 0.6781 - dense_2_12_accuracy: 0.7652 - dense_2_13_accuracy: 0.8321 - dense_2_14_accuracy: 0.8831 - dense_2_15_accuracy: 0.9212 - dense_2_16_accuracy: 0.9517 - dense_2_17_accuracy: 0.9752 - dense_2_18_accuracy: 0.9896 - dense_2_19_accuracy: 0.9995\n",
            "Epoch 3/10\n",
            "1562/1562 [==============================] - 442s 283ms/step - loss: 58.6773 - dense_2_loss: 5.0811 - dense_2_1_loss: 5.0699 - dense_2_2_loss: 5.2130 - dense_2_3_loss: 5.3408 - dense_2_4_loss: 5.3825 - dense_2_5_loss: 5.4060 - dense_2_6_loss: 5.3601 - dense_2_7_loss: 5.0973 - dense_2_8_loss: 4.4097 - dense_2_9_loss: 3.4940 - dense_2_10_loss: 2.6185 - dense_2_11_loss: 1.9630 - dense_2_12_loss: 1.4477 - dense_2_13_loss: 1.0389 - dense_2_14_loss: 0.7176 - dense_2_15_loss: 0.4910 - dense_2_16_loss: 0.3061 - dense_2_17_loss: 0.1613 - dense_2_18_loss: 0.0709 - dense_2_19_loss: 0.0077 - dense_2_accuracy: 0.1165 - dense_2_1_accuracy: 0.1252 - dense_2_2_accuracy: 0.1166 - dense_2_3_accuracy: 0.1147 - dense_2_4_accuracy: 0.1126 - dense_2_5_accuracy: 0.1154 - dense_2_6_accuracy: 0.1242 - dense_2_7_accuracy: 0.1707 - dense_2_8_accuracy: 0.2912 - dense_2_9_accuracy: 0.4442 - dense_2_10_accuracy: 0.5831 - dense_2_11_accuracy: 0.6875 - dense_2_12_accuracy: 0.7724 - dense_2_13_accuracy: 0.8372 - dense_2_14_accuracy: 0.8867 - dense_2_15_accuracy: 0.9238 - dense_2_16_accuracy: 0.9531 - dense_2_17_accuracy: 0.9761 - dense_2_18_accuracy: 0.9901 - dense_2_19_accuracy: 0.9996\n",
            "Epoch 4/10\n",
            "1562/1562 [==============================] - 443s 283ms/step - loss: 52.2164 - dense_2_loss: 4.9059 - dense_2_1_loss: 4.6566 - dense_2_2_loss: 4.6901 - dense_2_3_loss: 4.7721 - dense_2_4_loss: 4.7941 - dense_2_5_loss: 4.7711 - dense_2_6_loss: 4.7088 - dense_2_7_loss: 4.4556 - dense_2_8_loss: 3.8402 - dense_2_9_loss: 3.0253 - dense_2_10_loss: 2.2669 - dense_2_11_loss: 1.6891 - dense_2_12_loss: 1.2457 - dense_2_13_loss: 0.8974 - dense_2_14_loss: 0.6163 - dense_2_15_loss: 0.4156 - dense_2_16_loss: 0.2611 - dense_2_17_loss: 0.1369 - dense_2_18_loss: 0.0605 - dense_2_19_loss: 0.0069 - dense_2_accuracy: 0.1222 - dense_2_1_accuracy: 0.1536 - dense_2_2_accuracy: 0.1591 - dense_2_3_accuracy: 0.1625 - dense_2_4_accuracy: 0.1594 - dense_2_5_accuracy: 0.1664 - dense_2_6_accuracy: 0.1774 - dense_2_7_accuracy: 0.2241 - dense_2_8_accuracy: 0.3349 - dense_2_9_accuracy: 0.4814 - dense_2_10_accuracy: 0.6099 - dense_2_11_accuracy: 0.7076 - dense_2_12_accuracy: 0.7867 - dense_2_13_accuracy: 0.8462 - dense_2_14_accuracy: 0.8940 - dense_2_15_accuracy: 0.9289 - dense_2_16_accuracy: 0.9559 - dense_2_17_accuracy: 0.9778 - dense_2_18_accuracy: 0.9906 - dense_2_19_accuracy: 0.9995\n",
            "Epoch 5/10\n",
            "1562/1562 [==============================] - 441s 282ms/step - loss: 46.5663 - dense_2_loss: 4.6720 - dense_2_1_loss: 4.2690 - dense_2_2_loss: 4.2213 - dense_2_3_loss: 4.2770 - dense_2_4_loss: 4.2766 - dense_2_5_loss: 4.2232 - dense_2_6_loss: 4.1499 - dense_2_7_loss: 3.9065 - dense_2_8_loss: 3.3590 - dense_2_9_loss: 2.6349 - dense_2_10_loss: 1.9760 - dense_2_11_loss: 1.4595 - dense_2_12_loss: 1.0787 - dense_2_13_loss: 0.7737 - dense_2_14_loss: 0.5318 - dense_2_15_loss: 0.3568 - dense_2_16_loss: 0.2248 - dense_2_17_loss: 0.1180 - dense_2_18_loss: 0.0513 - dense_2_19_loss: 0.0064 - dense_2_accuracy: 0.1377 - dense_2_1_accuracy: 0.1957 - dense_2_2_accuracy: 0.2120 - dense_2_3_accuracy: 0.2168 - dense_2_4_accuracy: 0.2166 - dense_2_5_accuracy: 0.2288 - dense_2_6_accuracy: 0.2407 - dense_2_7_accuracy: 0.2849 - dense_2_8_accuracy: 0.3869 - dense_2_9_accuracy: 0.5220 - dense_2_10_accuracy: 0.6399 - dense_2_11_accuracy: 0.7322 - dense_2_12_accuracy: 0.8039 - dense_2_13_accuracy: 0.8590 - dense_2_14_accuracy: 0.9028 - dense_2_15_accuracy: 0.9347 - dense_2_16_accuracy: 0.9595 - dense_2_17_accuracy: 0.9793 - dense_2_18_accuracy: 0.9915 - dense_2_19_accuracy: 0.9995\n",
            "Epoch 6/10\n",
            "1562/1562 [==============================] - 441s 283ms/step - loss: 41.9166 - dense_2_loss: 4.4245 - dense_2_1_loss: 3.9303 - dense_2_2_loss: 3.8350 - dense_2_3_loss: 3.8655 - dense_2_4_loss: 3.8514 - dense_2_5_loss: 3.7769 - dense_2_6_loss: 3.6902 - dense_2_7_loss: 3.4622 - dense_2_8_loss: 2.9678 - dense_2_9_loss: 2.3259 - dense_2_10_loss: 1.7479 - dense_2_11_loss: 1.2860 - dense_2_12_loss: 0.9458 - dense_2_13_loss: 0.6773 - dense_2_14_loss: 0.4657 - dense_2_15_loss: 0.3127 - dense_2_16_loss: 0.1969 - dense_2_17_loss: 0.1039 - dense_2_18_loss: 0.0446 - dense_2_19_loss: 0.0060 - dense_2_accuracy: 0.1627 - dense_2_1_accuracy: 0.2410 - dense_2_2_accuracy: 0.2652 - dense_2_3_accuracy: 0.2718 - dense_2_4_accuracy: 0.2730 - dense_2_5_accuracy: 0.2877 - dense_2_6_accuracy: 0.3026 - dense_2_7_accuracy: 0.3446 - dense_2_8_accuracy: 0.4390 - dense_2_9_accuracy: 0.5623 - dense_2_10_accuracy: 0.6689 - dense_2_11_accuracy: 0.7544 - dense_2_12_accuracy: 0.8202 - dense_2_13_accuracy: 0.8711 - dense_2_14_accuracy: 0.9116 - dense_2_15_accuracy: 0.9405 - dense_2_16_accuracy: 0.9629 - dense_2_17_accuracy: 0.9811 - dense_2_18_accuracy: 0.9922 - dense_2_19_accuracy: 0.9994\n",
            "Epoch 7/10\n",
            "1562/1562 [==============================] - 442s 283ms/step - loss: 38.1918 - dense_2_loss: 4.1901 - dense_2_1_loss: 3.6413 - dense_2_2_loss: 3.5247 - dense_2_3_loss: 3.5302 - dense_2_4_loss: 3.5097 - dense_2_5_loss: 3.4203 - dense_2_6_loss: 3.3299 - dense_2_7_loss: 3.1138 - dense_2_8_loss: 2.6668 - dense_2_9_loss: 2.0885 - dense_2_10_loss: 1.5663 - dense_2_11_loss: 1.1519 - dense_2_12_loss: 0.8449 - dense_2_13_loss: 0.6054 - dense_2_14_loss: 0.4153 - dense_2_15_loss: 0.2808 - dense_2_16_loss: 0.1754 - dense_2_17_loss: 0.0912 - dense_2_18_loss: 0.0400 - dense_2_19_loss: 0.0055 - dense_2_accuracy: 0.1939 - dense_2_1_accuracy: 0.2856 - dense_2_2_accuracy: 0.3130 - dense_2_3_accuracy: 0.3224 - dense_2_4_accuracy: 0.3222 - dense_2_5_accuracy: 0.3433 - dense_2_6_accuracy: 0.3582 - dense_2_7_accuracy: 0.3979 - dense_2_8_accuracy: 0.4843 - dense_2_9_accuracy: 0.5973 - dense_2_10_accuracy: 0.6943 - dense_2_11_accuracy: 0.7747 - dense_2_12_accuracy: 0.8346 - dense_2_13_accuracy: 0.8821 - dense_2_14_accuracy: 0.9187 - dense_2_15_accuracy: 0.9451 - dense_2_16_accuracy: 0.9660 - dense_2_17_accuracy: 0.9826 - dense_2_18_accuracy: 0.9927 - dense_2_19_accuracy: 0.9993\n",
            "Epoch 8/10\n",
            "1562/1562 [==============================] - 442s 283ms/step - loss: 35.1960 - dense_2_loss: 3.9752 - dense_2_1_loss: 3.3990 - dense_2_2_loss: 3.2716 - dense_2_3_loss: 3.2607 - dense_2_4_loss: 3.2368 - dense_2_5_loss: 3.1382 - dense_2_6_loss: 3.0462 - dense_2_7_loss: 2.8416 - dense_2_8_loss: 2.4245 - dense_2_9_loss: 1.8993 - dense_2_10_loss: 1.4234 - dense_2_11_loss: 1.0482 - dense_2_12_loss: 0.7644 - dense_2_13_loss: 0.5499 - dense_2_14_loss: 0.3780 - dense_2_15_loss: 0.2549 - dense_2_16_loss: 0.1583 - dense_2_17_loss: 0.0842 - dense_2_18_loss: 0.0364 - dense_2_19_loss: 0.0051 - dense_2_accuracy: 0.2267 - dense_2_1_accuracy: 0.3254 - dense_2_2_accuracy: 0.3561 - dense_2_3_accuracy: 0.3643 - dense_2_4_accuracy: 0.3660 - dense_2_5_accuracy: 0.3880 - dense_2_6_accuracy: 0.4045 - dense_2_7_accuracy: 0.4428 - dense_2_8_accuracy: 0.5229 - dense_2_9_accuracy: 0.6287 - dense_2_10_accuracy: 0.7176 - dense_2_11_accuracy: 0.7914 - dense_2_12_accuracy: 0.8477 - dense_2_13_accuracy: 0.8905 - dense_2_14_accuracy: 0.9256 - dense_2_15_accuracy: 0.9494 - dense_2_16_accuracy: 0.9686 - dense_2_17_accuracy: 0.9836 - dense_2_18_accuracy: 0.9932 - dense_2_19_accuracy: 0.9994\n",
            "Epoch 9/10\n",
            "1562/1562 [==============================] - 441s 283ms/step - loss: 32.6787 - dense_2_loss: 3.7858 - dense_2_1_loss: 3.1904 - dense_2_2_loss: 3.0572 - dense_2_3_loss: 3.0280 - dense_2_4_loss: 3.0031 - dense_2_5_loss: 2.9025 - dense_2_6_loss: 2.8072 - dense_2_7_loss: 2.6101 - dense_2_8_loss: 2.2333 - dense_2_9_loss: 1.7501 - dense_2_10_loss: 1.3082 - dense_2_11_loss: 0.9624 - dense_2_12_loss: 0.6990 - dense_2_13_loss: 0.5017 - dense_2_14_loss: 0.3459 - dense_2_15_loss: 0.2342 - dense_2_16_loss: 0.1456 - dense_2_17_loss: 0.0763 - dense_2_18_loss: 0.0328 - dense_2_19_loss: 0.0049 - dense_2_accuracy: 0.2586 - dense_2_1_accuracy: 0.3617 - dense_2_2_accuracy: 0.3917 - dense_2_3_accuracy: 0.4031 - dense_2_4_accuracy: 0.4060 - dense_2_5_accuracy: 0.4269 - dense_2_6_accuracy: 0.4451 - dense_2_7_accuracy: 0.4807 - dense_2_8_accuracy: 0.5544 - dense_2_9_accuracy: 0.6517 - dense_2_10_accuracy: 0.7373 - dense_2_11_accuracy: 0.8053 - dense_2_12_accuracy: 0.8581 - dense_2_13_accuracy: 0.8993 - dense_2_14_accuracy: 0.9303 - dense_2_15_accuracy: 0.9524 - dense_2_16_accuracy: 0.9711 - dense_2_17_accuracy: 0.9846 - dense_2_18_accuracy: 0.9937 - dense_2_19_accuracy: 0.9994\n",
            "Epoch 10/10\n",
            "1562/1562 [==============================] - 441s 283ms/step - loss: 30.6359 - dense_2_loss: 3.6218 - dense_2_1_loss: 3.0211 - dense_2_2_loss: 2.8789 - dense_2_3_loss: 2.8433 - dense_2_4_loss: 2.8061 - dense_2_5_loss: 2.7115 - dense_2_6_loss: 2.6209 - dense_2_7_loss: 2.4334 - dense_2_8_loss: 2.0736 - dense_2_9_loss: 1.6265 - dense_2_10_loss: 1.2168 - dense_2_11_loss: 0.8916 - dense_2_12_loss: 0.6485 - dense_2_13_loss: 0.4659 - dense_2_14_loss: 0.3197 - dense_2_15_loss: 0.2155 - dense_2_16_loss: 0.1347 - dense_2_17_loss: 0.0706 - dense_2_18_loss: 0.0308 - dense_2_19_loss: 0.0046 - dense_2_accuracy: 0.2856 - dense_2_1_accuracy: 0.3908 - dense_2_2_accuracy: 0.4244 - dense_2_3_accuracy: 0.4346 - dense_2_4_accuracy: 0.4398 - dense_2_5_accuracy: 0.4574 - dense_2_6_accuracy: 0.4772 - dense_2_7_accuracy: 0.5100 - dense_2_8_accuracy: 0.5810 - dense_2_9_accuracy: 0.6722 - dense_2_10_accuracy: 0.7535 - dense_2_11_accuracy: 0.8173 - dense_2_12_accuracy: 0.8663 - dense_2_13_accuracy: 0.9041 - dense_2_14_accuracy: 0.9345 - dense_2_15_accuracy: 0.9551 - dense_2_16_accuracy: 0.9727 - dense_2_17_accuracy: 0.9855 - dense_2_18_accuracy: 0.9942 - dense_2_19_accuracy: 0.9993\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fbf892af160>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yGUThVQQZLwj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "56d19772-2fde-4284-8407-5edf6e18156e"
      },
      "source": [
        "model.save('/content/encoder_decoder_model_gru.h5')\n",
        "from google.colab import files\n",
        "files.download('/content/encoder_decoder_model_gru.h5')\n"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_d757b5a8-62e1-454c-9697-3e87a0c4c287\", \"encoder_decoder_model_gru.h5\", 157598904)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B1WC4p6G8ky3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "model = load_model('/content/encoder_decoder_model_moretrained.h5')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SfZnQQB4Ch0M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_sequence_argmax(input_seq):\n",
        "\n",
        "  target_seq = np.zeros((1,MAX_SEQ_LENGTH+1))\n",
        "  target_seq[0,0] = word_index[\"awwal\"]\n",
        "  target_seq = pad_sequences(target_seq,maxlen=MAX_SEQ_LENGTH,padding='post',truncating='post')\n",
        "  fed_seq = [input_seq,target_seq]\n",
        "  stop_condition = False\n",
        "  decoded_sentence = ''\n",
        "  for i in range(MAX_SEQ_LENGTH):\n",
        "    output = model.predict(fed_seq)\n",
        "    index_of_word = np.argmax(output[i])\n",
        "    if index_of_word==0:\n",
        "      predicted_word = 'zero'\n",
        "    else:\n",
        "      predicted_word = index_to_word[index_of_word]\n",
        "\n",
        "    if predicted_word == \"aakhir\":\n",
        "      break\n",
        "    else:\n",
        "      decoded_sentence+=\" \"+predicted_word\n",
        "\n",
        "    target_seq[0,i+1] = index_of_word\n",
        "    fed_seq = [input_seq,target_seq]\n",
        "\n",
        "  return decoded_sentence"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iK6-TLRxOTe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def decode_sequence_beam_search(input_seq,beam_width=3):\n",
        "  index_to_word[0] = \"\"\n",
        "  target_seq = np.zeros((beam_width,MAX_SEQ_LENGTH))#to store target sequences at different time steps\n",
        "  is_complete = []#if the given sequence has been ended by \"aakhir\" token\n",
        "  fed_seq = []#sequence to be fed to predict output\n",
        "  scores = np.zeros((beam_width,))#beam scores\n",
        "  for i in range(beam_width):\n",
        "    target_seq[i,0] = word_index[\"awwal\"]\n",
        "    fed_seq.append([input_seq,target_seq[i:i+1]])\n",
        "    is_complete.append(False)\n",
        "\n",
        "  for i in range(MAX_SEQ_LENGTH-1):\n",
        "    all_candidates = []#all possible beam_width*beam_width candidates at a given time step\n",
        "    all_scores = []#their scores\n",
        "    all_bool = []#if the given seq is complete\n",
        "    for j in range(beam_width):\n",
        "      if is_complete[j]: #if the seq is complete \n",
        "        all_candidates.append(np.array(target_seq[j]))\n",
        "        all_scores+=[scores[j]]\n",
        "        all_bool+=[is_complete[j]]\n",
        "        continue\n",
        "      output = model.predict(fed_seq[j])[i]\n",
        "\n",
        "      tmp_scores = scores[j]+np.log(output).reshape(vocab_size,) #(scores[j]*(i+1)+np.log(output).reshape(vocab_size,))/(i+2)  #length_normalization\n",
        "      indexes = np.argsort(-1*tmp_scores)[:beam_width]#top k candidates\n",
        "      scores_of_top = np.array([tmp_scores[i] for i in indexes])\n",
        "      tmp_bool = [index_to_word[i]==\"aakhir\" for i in indexes]\n",
        "\n",
        "      for index in indexes:\n",
        "        new_candidate = np.array(target_seq[j])\n",
        "        new_candidate[i+1] = index\n",
        "\n",
        "        all_candidates.append(new_candidate)\n",
        "      \n",
        "      all_scores+=list(scores_of_top)\n",
        "      all_bool+=tmp_bool\n",
        "\n",
        "    if i==0:\n",
        "      sorted_scores_indexes = np.arange(0,beam_width) #first k candidates bcoz symmetry imposed by awwal\n",
        "    else:\n",
        "      sorted_scores_indexes = np.argsort(-1*np.array(all_scores))[:beam_width] #top k candidates from all beams\n",
        "\n",
        "    target_seq = [all_candidates[i] for i in sorted_scores_indexes]\n",
        "    scores = [all_scores[i] for i in sorted_scores_indexes]\n",
        "    is_complete = [all_bool[i] for i in sorted_scores_indexes]\n",
        "\n",
        "    fed_seq = [[input_seq,np.array(t).reshape(1,MAX_SEQ_LENGTH)] for t in target_seq]\n",
        "\n",
        "  return target_seq,scores"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xaRw5TfiJs7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "96e0c244-eba9-44a5-fbf0-f789e175a4e4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[False, False, True, False, False, False]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mbR5-9vseQZl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e0da4f97-c0c4-4829-ca21-7c7d1387731f"
      },
      "source": [
        "inputs = [\"I AM EXTREMELY SAD TODAY\"]#[\"YOU BETTER GET SOME WORK TO DO\"]#[\"can ai overturn bureaucracy\"]#,\"give short outputs\",\"motherfucker\"]\n",
        "for input in inputs:\n",
        "  input = input.split()\n",
        "  input = tokenizer.texts_to_sequences([input])[0]\n",
        "  input = pad_sequences([input],maxlen=20,padding='post')\n",
        "  print(decode_sequence_argmax(input))"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " i can't see this guy's like this is a good of two years\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B_oyhG48_-_i",
        "colab_type": "text"
      },
      "source": [
        " i do know you time to the computer and <oov>\n",
        " i after know you know you will the tired place betray\n",
        " it hold you're mess sand him the man\n",
        " get negotiator you like you got a way reward"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GF9rnm_CefR-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "86bb9c2a-57b0-4901-f5b6-903f941a8f6f"
      },
      "source": [
        "inputs = [\"i hate ai\"]#[\"can ai overturn bureaucracy\",\"give short outputs\",\"motherfucker\",\"is the project complete\"]\n",
        "for input in inputs:\n",
        "  input = input.split()\n",
        "  input = tokenizer.texts_to_sequences([input])[0]\n",
        "  input = pad_sequences([input],maxlen=20,padding='post')\n",
        "  outputs,scores = decode_sequence_beam_search(input,beam_width=3)\n",
        "  for i in range(len(scores)):\n",
        "    s = ' '.join([index_to_word[t] for t in outputs[i]])\n",
        "    print(s,scores[i])"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "awwal i don't wanna be a good time to tell aakhir          -16.349768\n",
            "awwal i don't wanna be a good time to do this aakhir         -17.712975\n",
            "awwal i don't wanna be a good time but if you did to do aakhir      -20.26361\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JS19tP9gfL5F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}